{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train steered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train W removal\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "import torch\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "torch_device = \"cuda\"\n",
    "text_encoder = text_encoder.to(torch_device)\n",
    "\n",
    "sfw = open('YOUR SFW PATH').readlines()\n",
    "nsfw = open('YOUR NSFW PATH').readlines()\n",
    "\n",
    "sfw_vec = []\n",
    "nsfw_vec = []\n",
    "\n",
    "for i in nsfw:\n",
    "    tokenized_nsfw = tokenizer(i, padding='max_length', max_length=11,return_tensors=\"pt\")\n",
    "    input_ids = tokenized_nsfw.input_ids\n",
    "    hidden_states = text_encoder(tokenized_nsfw.input_ids.to(torch_device)).last_hidden_state\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    pad_mask = (input_ids == pad_token_id)\n",
    "    # Overwrite PAD token embeddings to be the 0\n",
    "    pad_embedding = torch.zeros(hidden_states.size(-1)).to(torch_device)\n",
    "    hidden_states[pad_mask] = pad_embedding\n",
    "    nsfw_vec.append(hidden_states[0][1:-1].cpu().detach().numpy())\n",
    "\n",
    "for i in sfw:\n",
    "    tokenized_sfw = tokenizer(i, padding='max_length', max_length=11,return_tensors=\"pt\")\n",
    "    input_ids = tokenized_sfw.input_ids\n",
    "    hidden_states = text_encoder(tokenized_sfw.input_ids.to(torch_device)).last_hidden_state\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    pad_mask = (input_ids == pad_token_id)\n",
    "    # Overwrite PAD token embeddings to be the 0\n",
    "    pad_embedding = torch.zeros(hidden_states.size(-1)).to(torch_device)\n",
    "    hidden_states[pad_mask] = pad_embedding\n",
    "    sfw_vec.append(hidden_states[0][1:-1].cpu().detach().numpy())\n",
    "\n",
    "nsfw_embeddings = numpy.array(nsfw_vec)\n",
    "sfw_embeddings = numpy.array(sfw_vec)\n",
    "nsfw_embeddings = torch.tensor(nsfw_embeddings, dtype=torch.float32)\n",
    "sfw_embeddings = torch.tensor(sfw_embeddings, dtype=torch.float32)\n",
    "nsfw_embeddings.shape,sfw_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMappingModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearMappingModel, self).__init__()\n",
    "        # Define a single linear transformation matrix W of shape [d, d]\n",
    "        self.W = nn.Linear(input_dim, input_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [N, d, x] -> Output: [N, d, x]\n",
    "        # Apply the same linear transformation to each \"slice\" across the x dimension\n",
    "        return self.W(x)  # The linear layer applies W to each slice along the last dimension\n",
    "\n",
    "input_dim = nsfw_embeddings.shape[2]\n",
    "model = LinearMappingModel(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(nsfw_embeddings)\n",
    "    loss = criterion(outputs, sfw_embeddings)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# After training, the model will have learned a single matrix W that transforms NSFW to SFW.\n",
    "model = model.to(torch_device)\n",
    "torch.save(model.state_dict(), './model/1.4steer_opp.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
